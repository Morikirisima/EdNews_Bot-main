import urllib3
import warnings



import requests
from bs4 import BeautifulSoup
from datetime import datetime
from database.models.models import Post

from utils.filters import is_advertisement_content, needs_manual_review
import config
import re
import asyncio
import os

# ========== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø GIGACHAT ==========

GIGACHAT_API_URL = "https://gigachat.devices.sberbank.ru/api/v1/chat/completions"
print("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏...")

GIGACHAT_ACCESS_TOKEN = getattr(config, 'GIGACHAT_ACCESS_TOKEN', None)

print(f"–¢–æ–∫–µ–Ω –∏–∑ config: {GIGACHAT_ACCESS_TOKEN}")

if not GIGACHAT_ACCESS_TOKEN:
    GIGACHAT_ACCESS_TOKEN = os.getenv("GIGACHAT_ACCESS_TOKEN")
    print(f"–¢–æ–∫–µ–Ω –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è: {GIGACHAT_ACCESS_TOKEN}")
    if not GIGACHAT_ACCESS_TOKEN:
        print("‚ùå GIGACHAT_ACCESS_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        GIGACHAT_ACCESS_TOKEN = "test_token"
    else:
        print("‚úÖ –¢–æ–∫–µ–Ω –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
else:
    print("‚úÖ –¢–æ–∫–µ–Ω –Ω–∞–π–¥–µ–Ω –≤ config")

print(f"–ò—Ç–æ–≥–æ–≤—ã–π —Ç–æ–∫–µ–Ω: {GIGACHAT_ACCESS_TOKEN[:20]}..." if GIGACHAT_ACCESS_TOKEN and len(GIGACHAT_ACCESS_TOKEN) > 20 else f"–ò—Ç–æ–≥–æ–≤—ã–π —Ç–æ–∫–µ–Ω: {GIGACHAT_ACCESS_TOKEN}")
GIGACHAT_MODEL = "GigaChat"
GIGACHAT_MAX_TOKENS = 500
GIGACHAT_TEMPERATURE = 0.3

SYSTEM_PROMPT = """–¢—ã - –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç—ã —Å—Ç–∞—Ç–µ–π, –¥–µ–ª–∞—è –∏—Ö –±–æ–ª–µ–µ —á–∏—Ç–∞–µ–º—ã–º–∏ –±–µ–∑ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è."""

USER_PROMPT_TEMPLATE = """–û–±—Ä–∞–±–æ—Ç–∞–π —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º:

{text}"""

ADVERTISING_KEYWORD = "[ADVERTISING]"
PROHIBITED_KEYWORD = "[PROHIBITED]"


class EnhancedParser:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })

    async def parse_new_posts(self) -> list:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        try:
            print(f"üîç –ü–∞—Ä—Å–∏–º {config.PARSER_URL}")
            response = self.session.get(config.PARSER_URL)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, 'html5lib')

            posts_data = self._extract_posts(soup)
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(posts_data)} –ø–æ—Å—Ç–æ–≤")

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç—ã —á–µ—Ä–µ–∑ GigaChat
            processed_posts = await self._process_with_gigachat(posts_data)

            return processed_posts

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
            return []

    def _extract_posts(self, soup) -> list:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–æ—Å—Ç—ã - —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è"""
        posts = []

        print("üîç –ü–æ–∏—Å–∫ —Å—Ç–∞—Ç–µ–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ...")

        # –ü—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–±: –∏—â–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏ –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–≥–ª—è–¥—è—Ç –∫–∞–∫ —Å—Ç–∞—Ç—å–∏
        links = soup.find_all('a', href=True)

        for link in links:
            href = link['href']
            text = link.get_text(strip=True)

            # –§–∏–ª—å—Ç—Ä—É–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å—Ç–∞—Ç—å–∏
            if (href and
                    ('/20' in href or '/news' in href or '/article' in href) and
                    len(text) > 10 and
                    not href.startswith(('javascript:', 'mailto:', '#'))):

                # –°–æ–∑–¥–∞–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–π URL
                if href.startswith('/'):
                    url = 'https://rg.ru' + href
                else:
                    url = href

                # –°–æ–∑–¥–∞–µ–º –ø–æ—Å—Ç
                post_data = {
                    'title': text,
                    'preview_content': "",
                    'original_content': "",
                    'processed_content': "",
                    'source_url': url,
                    'published_at': datetime.now(),
                    'image_url': "",
                    'is_valid': True
                }

                # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç
                if url:
                    post_data['original_content'] = self._get_full_content(url)

                posts.append(post_data)
                print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω –ø–æ—Å—Ç: {text[:60]}...")

        return posts

    def _parse_article(self, article) -> dict:
        """–ü–∞—Ä—Å–∏—Ç –æ—Ç–¥–µ–ª—å–Ω—É—é —Å—Ç–∞—Ç—å—é —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        try:
            title_elem = (article.find('h3') or
                          article.find('h2') or
                          article.find('span', class_='ItemOfListStandard_title__Ajjlf') or
                          article.find('a').find('span') if article.find('a') else None)

            title = title_elem.get_text().strip() if title_elem else "–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞"

            if not title or title == "–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞":
                return self._create_invalid_post("–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞")

            link_elem = article.find('a')
            url = link_elem.get('href') if link_elem else ""
            if url and url.startswith('/'):
                url = 'https://rg.ru' + url

            content_elem = (article.find('p') or
                            article.find('div', class_='preview') or
                            article.find('div', class_='ItemOfListStandard_announce__cOc_i'))
            preview_content = content_elem.get_text().strip() if content_elem else ""

            full_content = ""
            if url:
                full_content = self._get_full_content(url)

            return {
                'title': title,
                'preview_content': preview_content,
                'original_content': full_content,
                'processed_content': "",
                'source_url': url,
                'published_at': datetime.now(),
                'image_url': self._extract_image(article),
                'is_valid': True
            }

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç–∞—Ç—å–∏: {e}")
            return self._create_invalid_post(f"–û—à–∏–±–∫–∞: {str(e)}")

    @staticmethod
    def _create_invalid_post(title: str) -> dict:
        """–°–æ–∑–¥–∞–µ—Ç –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π –ø–æ—Å—Ç (—Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π –º–µ—Ç–æ–¥)"""
        return {
            'title': title,
            'preview_content': "",
            'original_content': "",
            'processed_content': "",
            'source_url': "",
            'published_at': datetime.now(),
            'image_url': "",
            'is_valid': False
        }
    @staticmethod
    def _extract_image(article) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (—Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π –º–µ—Ç–æ–¥)"""
        try:
            image_element = article.find('div', class_='ImageIcon_root__XuGMY')
            if not image_element:
                image_element = article.find('img')

            if image_element:
                img_tag = image_element.find('img') if image_element.name == 'div' else image_element
                if img_tag and img_tag.get('src'):
                    img_url = img_tag['src']
                    if img_url.startswith('//'):
                        img_url = 'https:' + img_url
                    elif img_url.startswith('/'):
                        img_url = 'https://rg.ru' + img_url
                    return img_url
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")

        return ""

    def _get_full_content(self, url: str) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏"""
        try:
            if not url:
                return ""

            print(f"    üìñ –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç: {url}")
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, 'html.parser')

            content_blocks = [
                soup.find('div',
                          class_='PageContentCommonStyling_text__CKOzO commonArticle_text__ul5uZ commonArticle_zoom__SDMjc'),
                soup.find('div', class_='PageArticleContent_lead__l9TkG commonArticle_zoom__SDMjc'),
                soup.find('div', class_='PageContentCommonStyling_text__CKOzO'),
                soup.find('div', class_='article-content'),
                soup.find('div', class_='article-body'),
                soup.find('article')
            ]

            article_text = ""
            for block in content_blocks:
                if block:
                    paragraphs = block.find_all('p')
                    for p in paragraphs:
                        text = p.get_text(strip=True)
                        if text and len(text) > 10:
                            article_text += text + "\n\n"

                    if article_text:
                        print(f"    ‚úÖ –ù–∞–π–¥–µ–Ω —Ç–µ–∫—Å—Ç: {len(article_text)} —Å–∏–º–≤–æ–ª–æ–≤")
                        article_text = re.sub(r'\n\s*\n', '\n\n', article_text.strip())
                        return article_text

            if not article_text:
                all_paragraphs = soup.find_all('p')
                for p in all_paragraphs:
                    text = p.get_text(strip=True)
                    if text and len(text) > 50:
                        article_text += text + "\n\n"

                if article_text:
                    print(f"    ‚ö†Ô∏è –¢–µ–∫—Å—Ç –Ω–∞–π–¥–µ–Ω —á–µ—Ä–µ–∑ fallback: {len(article_text)} —Å–∏–º–≤–æ–ª–æ–≤")
                    return article_text

            print("    ‚ùå –¢–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return ""

        except Exception as e:
            print(f"    ‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞: {e}")
            return f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {str(e)}"

    async def _process_with_gigachat(self, posts_data: list) -> list:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç—ã —á–µ—Ä–µ–∑ GigaChat API"""
        processed_posts = []

        for post_data in posts_data:
            if not post_data or not post_data.get('is_valid', True):
                print(f"    ‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π –ø–æ—Å—Ç: {post_data.get('title', 'No title')}")
                continue

            original_text = post_data.get('original_content', '')

            if not original_text or len(original_text) < 300:
                post_data['processed_content'] = original_text
                post_data['processing_status'] = 'too_short'
                processed_posts.append(post_data)
                continue

            try:
                print(f"    ü§ñ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ GigaChat: {post_data['title'][:50]}...")
                # –£–±–∏—Ä–∞–µ–º await –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞
                processed_text = self._call_gigachat_api(original_text)

                if processed_text == ADVERTISING_KEYWORD:
                    post_data['processed_content'] = original_text
                    post_data['processing_status'] = 'advertising'
                    post_data['is_valid'] = False
                    print(f"    ‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —Ä–µ–∫–ª–∞–º–∞: {post_data['title'][:50]}...")

                elif processed_text == PROHIBITED_KEYWORD:
                    post_data['processed_content'] = original_text
                    post_data['processing_status'] = 'prohibited'
                    post_data['is_valid'] = False
                    print(f"    ‚ö†Ô∏è –ó–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç: {post_data['title'][:50]}...")

                else:
                    original_len = len(original_text)
                    processed_len = len(processed_text)

                    if processed_len < 50:
                        post_data['processed_content'] = original_text
                        post_data['processing_status'] = 'api_error'
                        print(f"    ‚ö†Ô∏è –û—à–∏–±–∫–∞ API (–∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç): {post_data['title'][:50]}...")
                    else:
                        post_data['processed_content'] = processed_text
                        post_data['processing_status'] = 'processed'
                        reduction = ((original_len - processed_len) / original_len) * 100
                        print(
                            f"    ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω: {post_data['title'][:50]}... ({processed_len}/{original_len} chars, -{reduction:.1f}%)")

                processed_posts.append(post_data)
                await asyncio.sleep(1)  # –û—Å—Ç–∞–≤–ª—è–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏

            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ GigaChat: {e}")
                post_data['processed_content'] = original_text
                post_data['processing_status'] = 'api_error'
                processed_posts.append(post_data)

        return processed_posts

    @staticmethod
    def _call_gigachat_api(text: str) -> str:
        """–í—ã–∑—ã–≤–∞–µ—Ç GigaChat API –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞"""
        try:
            headers = {
                'Content-Type': 'application/json',
                'Authorization': f'Bearer {GIGACHAT_ACCESS_TOKEN}',
                'Accept': 'application/json'
            }

            payload = {
                "model": GIGACHAT_MODEL,
                "messages": [
                    {
                        "role": "system",
                        "content": SYSTEM_PROMPT
                    },
                    {
                        "role": "user",
                        "content": USER_PROMPT_TEMPLATE.format(text=text)
                    }
                ],
                "max_tokens": GIGACHAT_MAX_TOKENS,
                "temperature": GIGACHAT_TEMPERATURE
            }

            response = requests.post(
                GIGACHAT_API_URL,
                headers=headers,
                json=payload,
                timeout=30,
                verify=False  # ‚Üê –î–û–ë–ê–í–¨ –≠–¢–£ –°–¢–†–û–ö–£ –î–õ–Ø –û–¢–ö–õ–Æ–ß–ï–ù–ò–Ø SSL –ü–†–û–í–ï–†–ö–ò
            )

            response.raise_for_status()
            result = response.json()
            return result['choices'][0]['message']['content']

        except Exception as e:
            print(f"    ‚ùå –û—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ GigaChat API: {e}")
            raise

async def process_parsed_posts(posts_data: list) -> list:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–µ –ø–æ—Å—Ç—ã: —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç–∞—Ç—É—Å—ã"""
    processed_posts = []

    for post_data in posts_data:
        if not post_data or not post_data.get('is_valid', True):
            continue

        content_for_filtering = post_data.get('processed_content') or post_data.get('original_content', '')
        full_text = f"{post_data['title']} {content_for_filtering}"

        processing_status = post_data.get('processing_status', '')

        if (processing_status in ['advertising', 'prohibited'] or
                is_advertisement_content(full_text)):
            status = "rejected"
            print(f"üö´ –û—Ç–∫–ª–æ–Ω–µ–Ω: {post_data['title'][:50]}...")

        elif (processing_status == 'api_error' or
              needs_manual_review(full_text) or
              not post_data.get('source_url')):
            status = "draft"
            print(f"üìù –ù–∞ –º–æ–¥–µ—Ä–∞—Ü–∏—é: {post_data['title'][:50]}...")

        else:
            status = "parsed"
            print(f"‚úÖ –í –æ—á–µ—Ä–µ–¥—å: {post_data['title'][:50]}...")

        processed_posts.append({
            **post_data,
            'status': status,
            'needs_review': status == "draft"
        })

    return processed_posts


async def save_posts_to_db(posts: list, db_session):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–æ—Å—Ç—ã –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º"""
    from sqlalchemy import select

    saved_count = 0
    skipped_count = 0

    for post_data in posts:
        if not post_data or not post_data.get('is_valid', True):
            skipped_count += 1
            continue

        try:
            # –§–ò–ö–°: –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ SQLAlchemy –≤ —É—Å–ª–æ–≤–∏–∏ WHERE
            if post_data.get('source_url'):
                existing_post = await db_session.execute(
                    select(Post).where(Post.source_url == post_data['source_url'])
                )
                if existing_post.scalar():
                    print(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç: {post_data['title'][:50]}...")
                    skipped_count += 1
                    continue

            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –ø–æ—Å—Ç
            new_post = Post(
                title=post_data['title'],
                content=post_data.get('processed_content') or post_data.get('original_content', ''),
                source_url=post_data.get('source_url', ''),
                status=post_data['status'],
                preview_content=post_data.get('preview_content', ''),
                original_content=post_data.get('original_content', ''),
                image_url=post_data.get('image_url', ''),
                processing_status=post_data.get('processing_status', 'not_processed'),
                published_at=post_data.get('published_at', datetime.now())
            )

            db_session.add(new_post)
            saved_count += 1
            print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω: {post_data['title'][:50]}... (—Å—Ç–∞—Ç—É—Å: {post_data['status']})")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ—Å—Ç–∞ {post_data.get('title', 'Unknown')}: {e}")
            skipped_count += 1
            continue

    try:
        await db_session.commit()
        print(f"üíæ –í—Å–µ–≥–æ: {len(posts)} –ø–æ—Å—Ç–æ–≤, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {saved_count}, –ø—Ä–æ–ø—É—â–µ–Ω–æ: {skipped_count}")
        return saved_count
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–º–º–∏—Ç–∞ –≤ –ë–î: {e}")
        await db_session.rollback()
        return 0

